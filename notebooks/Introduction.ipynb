{
 "metadata": {
  "name": "",
  "signature": "sha256:5ea6218c35af8ca97f2e19588bfb51770ed405f19d27ce636e8508c282318d45"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Enable logging\n",
      "import logging\n",
      "logger = logging.getLogger()\n",
      "logger.setLevel(logging.INFO)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## A simple prediction workflow"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Drain workflows consist of `drain.step.Step` objects. Take for example the `drain.data.ClassificationData` step:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import drain.data\n",
      "data = drain.data.ClassificationData(target=True, n_samples=1000, n_features=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This step calls the `sklearn.datasets.make_classification` method to generate a dataset with a binary outcome. We can run the step by step by calling its `execute` method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.execute()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tClassificationData(n_features=100, n_samples=1000)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "{'X':            0         1         2         3         4         5         6   \\\n",
        " 0   -1.254740  1.568295  0.859270 -0.663371  0.356787 -0.638139  0.429711   \n",
        " 1   -1.239955 -2.459949  0.264857  0.192786 -1.293184 -0.803018  1.693877   \n",
        " 2   -0.485544  0.852361  2.351547 -0.438737 -1.006562 -0.383894  0.911859   \n",
        " 3    1.407038 -0.930342  2.072200  0.270287  0.978798 -2.089569  0.444492   \n",
        " 4    1.355452  0.994878  0.590868 -0.154992  1.435196  1.124019  1.160561   \n",
        " 5    0.660716  2.346761 -1.220935 -1.001100 -0.943435  1.055353 -0.098777   \n",
        " 6    0.821727  0.507412  0.020194  0.618511  0.420213 -0.889522 -0.822467   \n",
        " 7    0.560941 -2.194889 -2.288383  0.137653 -0.608870 -0.321122 -2.200869   \n",
        " 8    0.826213  0.502941  1.617814 -0.395790  1.123574 -0.477804  0.544032   \n",
        " 9   -0.859297  0.507568 -0.173425  0.478020 -0.120310  1.010425 -0.465142   \n",
        " 10  -0.181034 -1.480597  1.076036  0.297779  2.611382 -1.110131 -0.792575   \n",
        " 11   0.363537 -0.978450 -0.600857 -0.646410 -0.098534 -0.409467  2.197751   \n",
        " 12   0.993590  1.295459  0.795243 -0.014217 -0.997072  0.302877 -1.127455   \n",
        " 13  -0.279930  0.991420  0.345867  0.862786 -0.991938  0.533575  0.366574   \n",
        " 14  -1.081655 -0.440487 -1.961790 -0.609297 -1.387298 -1.895199 -0.994840   \n",
        " 15   1.492068  0.157100  0.759088 -1.610228 -0.939882  1.123338 -0.938158   \n",
        " 16  -0.101319 -0.058831 -0.097279  0.384583  0.054213  0.787314 -0.738299   \n",
        " 17   0.634146 -1.511758  1.043389  1.037083 -0.694244 -2.113977 -0.735913   \n",
        " 18   0.530260 -0.821921  2.889919  0.128075 -0.089201 -1.135251 -1.109900   \n",
        " 19   0.383313  1.288586  0.630922 -0.278463 -0.576125  0.527565  0.155685   \n",
        " 20   0.619015 -0.218414  0.381265 -0.450987  0.320198  0.551846 -0.760200   \n",
        " 21   0.590202 -0.349106  0.104717 -0.094581 -0.812437  1.137110 -0.558482   \n",
        " 22  -0.792744  0.625676 -1.219969 -1.086694  0.015019  0.654400 -0.093755   \n",
        " 23   0.090251  0.573517 -0.392694 -0.900419 -0.632813  0.021403 -0.150404   \n",
        " 24   1.595944  1.393577  1.196274 -1.040089 -0.301914  0.252948  0.449126   \n",
        " 25  -1.010943  0.844200  2.811122 -1.014319 -0.454213 -0.135180  0.544227   \n",
        " 26   0.611729  1.130267  1.297125 -0.278936 -0.696657 -0.399766  1.109386   \n",
        " 27   2.030651 -0.197337  0.511531 -0.052648  0.374089 -0.184860 -0.391595   \n",
        " 28   1.553720 -0.907226 -0.530793  0.408559  0.304652  1.444174 -0.447947   \n",
        " 29  -0.132642  1.204381  0.321965  1.453492 -0.277177  0.360333  1.902768   \n",
        " ..        ...       ...       ...       ...       ...       ...       ...   \n",
        " 970  1.427974  0.199819 -0.411418  1.498040  0.194273  1.383671 -0.863180   \n",
        " 971 -0.375810  0.708675  0.472280  0.557209 -1.220460 -0.318778  1.554513   \n",
        " 972  1.259005 -2.024813 -0.166037 -1.117739 -1.174340  0.000942 -0.189614   \n",
        " 973 -0.082218  0.618799 -0.785486 -0.993933  0.083065  0.342710 -0.406177   \n",
        " 974  0.573386  0.583677  0.456756  1.093332  0.440058 -0.662806 -0.879922   \n",
        " 975  1.396891 -0.173375  0.316951  0.933275 -1.138031 -0.266611  0.359347   \n",
        " 976 -0.802807  0.811760  0.315390  1.027934 -0.383143 -0.289900  0.564009   \n",
        " 977  0.572079 -0.525685 -0.969152 -0.168889  0.134876  0.094651  0.706020   \n",
        " 978 -1.010922 -0.137452  0.805744  1.052817  0.564659  0.023036  1.262760   \n",
        " 979  1.662119 -1.446498  1.107810  0.856095  2.265605 -0.901305 -0.717911   \n",
        " 980  1.399542 -2.517785  1.670611  0.993417 -0.638496 -1.284510  0.178300   \n",
        " 981  0.856778  0.973065 -0.293322  1.148104 -1.982842 -0.395618  0.737356   \n",
        " 982 -1.123017 -0.452388  0.966455  0.463871  2.083240 -0.282247  2.820722   \n",
        " 983  1.020074  0.632911  0.326278 -1.382778  0.522737  0.360319 -1.327267   \n",
        " 984 -0.399732 -1.112838  0.297023 -1.671867 -0.465824  0.433053  1.253564   \n",
        " 985 -0.578588 -1.041905 -0.513800  0.593854 -0.945068 -0.228836 -0.230977   \n",
        " 986 -1.600228  0.002392 -1.151025 -0.511848  0.847090  0.474955 -0.490107   \n",
        " 987 -0.153341 -0.707808  1.036295  0.465421 -0.048909 -0.869606 -0.773781   \n",
        " 988 -0.224466  0.819665  0.234562  1.742887 -0.733612  1.056107  0.077367   \n",
        " 989  1.673015 -0.703000 -0.912050 -0.346017  1.415573  0.972629 -1.073629   \n",
        " 990  0.375088 -2.157032 -0.962757 -0.016289  0.379584  0.724160 -0.729455   \n",
        " 991  0.471328 -0.536188  1.377669 -0.419758 -0.565780  0.624298  0.002458   \n",
        " 992 -0.817988 -1.055492  0.580356 -1.444357  1.006731 -1.187316  0.541494   \n",
        " 993 -0.211229  1.535913  0.689260  0.766016  0.424826 -0.947540 -0.560268   \n",
        " 994 -0.218786 -1.943115  0.389745 -0.177236 -0.244490 -0.232373  0.186143   \n",
        " 995  0.197082  0.149167 -0.396804  0.409610  1.961823 -0.063628  0.163441   \n",
        " 996 -1.145868 -1.140588  0.035049  0.941297  0.528853 -0.285471  1.943755   \n",
        " 997 -0.436684 -0.539361 -0.377773 -1.406364 -0.884543  0.200418  1.271856   \n",
        " 998 -0.408406 -0.058132 -0.210153  1.311349 -0.561259  0.054425  1.618026   \n",
        " 999  1.086343 -0.507914  1.941163  1.794463 -0.025451  0.037245  0.399774   \n",
        " \n",
        "            7         8         9     ...           90        91        92  \\\n",
        " 0   -0.317344  0.649796  0.435950    ...     1.692325 -0.800594  0.291897   \n",
        " 1    1.397676  0.582380  1.845770    ...    -1.346165 -0.515097 -0.986927   \n",
        " 2   -0.301803 -0.966162  0.635666    ...     0.821978  1.543093  1.440337   \n",
        " 3    0.510186  0.612589 -0.647749    ...    -1.200731  0.286586 -0.019840   \n",
        " 4    1.137675 -0.919961  0.457479    ...    -0.732394  0.842354  0.257231   \n",
        " 5   -0.212021  1.854793  0.091716    ...    -1.147652  0.220629 -0.875983   \n",
        " 6    0.677341 -0.694924 -0.439465    ...     0.945848 -1.082315 -0.465580   \n",
        " 7   -1.135885  2.231805  1.238442    ...    -0.809847  1.044542  1.007487   \n",
        " 8   -1.552876  0.425295  0.747201    ...     0.270946  0.278733 -1.100260   \n",
        " 9   -0.616774 -0.215404  0.236690    ...    -0.622256 -0.221961 -0.197931   \n",
        " 10  -1.365648 -1.447118  0.561395    ...     0.398376  1.077897 -0.321834   \n",
        " 11  -0.629822 -2.140771  1.535139    ...    -1.900833  0.874642  0.567859   \n",
        " 12   0.049380 -0.531111  1.098333    ...    -0.560815  0.077198  1.000120   \n",
        " 13   1.579323  0.128987 -0.642869    ...    -2.101945  0.514262 -0.840356   \n",
        " 14   0.498721 -0.079305  0.549055    ...     0.646890  1.128414  0.482017   \n",
        " 15  -2.083341  0.622965 -0.990498    ...     1.337750  0.619105 -0.709034   \n",
        " 16  -0.320129 -1.452961  0.194205    ...     0.583090  0.327822 -0.228025   \n",
        " 17  -2.205644  0.176696  0.061404    ...     1.011616 -0.390736  0.571668   \n",
        " 18  -0.224665 -1.211889  0.673980    ...     1.988059 -0.763888 -0.044132   \n",
        " 19  -0.149820  0.534449  0.515180    ...    -0.380617 -1.285820  0.065645   \n",
        " 20   2.469470 -0.365862 -0.489380    ...    -1.189763  0.235829  0.929609   \n",
        " 21  -0.345152 -1.156759  0.511396    ...    -0.239752 -1.003209  1.015141   \n",
        " 22  -1.563144 -0.783295  0.195164    ...    -0.646349  0.807345 -0.889528   \n",
        " 23  -1.105089  0.125311 -0.441498    ...     0.317951 -1.686191  2.279539   \n",
        " 24  -0.371268  0.716161  0.500363    ...     0.698846  0.263003  1.193694   \n",
        " 25  -1.843775 -0.708209 -0.390841    ...     0.120863  1.577266  0.608153   \n",
        " 26  -0.183411  0.943761 -0.539840    ...    -2.392502 -1.724615 -0.790046   \n",
        " 27  -0.685548  0.658868 -0.129957    ...     0.789021  0.480574  0.485108   \n",
        " 28   0.394668  0.927867  0.474594    ...     1.017249  0.233735 -0.865090   \n",
        " 29   0.875193 -0.648333 -0.618216    ...     1.154525 -1.282005  0.426993   \n",
        " ..        ...       ...       ...    ...          ...       ...       ...   \n",
        " 970  1.584451  0.898695  0.950156    ...    -1.198896 -1.500364  0.147468   \n",
        " 971 -1.516772  0.942546 -0.306998    ...    -0.838506 -1.165612 -0.009636   \n",
        " 972 -1.303565 -1.562939 -0.525488    ...    -0.811399 -0.908523  1.115758   \n",
        " 973  0.923340 -0.346517  1.274084    ...     0.140783 -0.202236 -0.550950   \n",
        " 974 -1.416193 -0.376203 -0.435894    ...    -0.377619  1.307645  0.067711   \n",
        " 975 -0.720587  1.449158  0.140012    ...     0.779804  0.350238 -1.225247   \n",
        " 976  0.880073 -1.031125  0.438087    ...     0.890204  0.179396 -2.010895   \n",
        " 977 -2.360070  0.105652  1.200624    ...     1.799642  0.361594 -0.252854   \n",
        " 978 -0.364856  1.518637  0.861621    ...     1.076710  0.410516 -0.179108   \n",
        " 979  0.081220 -0.436517 -0.313258    ...    -0.378749 -0.365762  0.165117   \n",
        " 980 -1.173198 -0.139173 -1.866092    ...     0.225117  0.652381 -1.784381   \n",
        " 981 -0.109078 -0.928463 -1.327946    ...     1.048008 -0.455142 -1.138962   \n",
        " 982 -1.072128  0.403995  0.863175    ...     0.399199  0.355422 -0.725796   \n",
        " 983 -0.450487  0.572312 -0.441018    ...    -0.067267  1.245170 -0.174082   \n",
        " 984  0.061257 -0.276346 -1.053986    ...     0.681992  0.289140  0.091927   \n",
        " 985  0.158640 -0.543643  0.802841    ...    -1.078982  0.500068  0.456649   \n",
        " 986 -1.074230  0.185078 -0.513902    ...    -0.231571  0.325234 -0.160442   \n",
        " 987 -1.414793  0.466396 -0.789620    ...    -0.314411  2.439750 -0.029362   \n",
        " 988 -1.895999 -1.315336  1.379091    ...     0.228738  1.346434 -1.150442   \n",
        " 989 -0.991179  0.789371  0.982003    ...    -0.794618 -1.037488  0.548931   \n",
        " 990  0.022600  0.354721 -0.526454    ...    -0.499464 -0.026963  0.854360   \n",
        " 991  1.111153 -0.106708 -0.752531    ...     1.489186 -0.196638 -0.542070   \n",
        " 992 -0.752222  0.103705  0.011176    ...    -0.270127  2.142073 -1.645180   \n",
        " 993  0.839112 -0.945992 -0.722982    ...    -2.953682 -0.393865 -0.660461   \n",
        " 994 -1.661020  0.616278 -1.296305    ...     1.159081  0.023756  0.302573   \n",
        " 995  0.561612 -1.107007  0.915307    ...    -0.305321 -0.547401 -0.441435   \n",
        " 996 -1.472651  0.024061 -0.866942    ...     0.612108  0.413757 -1.376710   \n",
        " 997  0.520302  1.444479  0.158747    ...     0.195213  0.755401  0.130984   \n",
        " 998  0.226956  0.317800 -0.299309    ...     0.930140  0.782400  0.267767   \n",
        " 999  0.528914 -0.559269  1.971265    ...     0.799492 -0.659607 -0.256106   \n",
        " \n",
        "            93        94        95        96        97        98        99  \n",
        " 0   -0.453697 -0.178751 -0.607489  1.037445 -1.749688 -0.607751  0.357977  \n",
        " 1    0.102077  1.496402 -0.646635 -0.417379 -0.302278  0.201746  1.240888  \n",
        " 2    0.181615  0.403379 -0.271970  0.417755 -2.832542  0.968731 -1.794433  \n",
        " 3    0.763633  0.140741 -0.008938  0.925198  0.656512 -0.018097 -0.824847  \n",
        " 4   -0.763106 -1.773781  0.791774 -1.135354 -0.736330  0.631639 -0.533620  \n",
        " 5   -0.411940 -0.822743 -1.680231 -1.000032  0.551767 -2.749766  0.482842  \n",
        " 6    0.241179 -2.002802 -1.462483  2.470792  1.039311 -0.951879 -1.283762  \n",
        " 7    0.518928 -0.603663  0.734483  2.258332 -0.339975 -0.028964  0.222319  \n",
        " 8   -1.517364 -0.020546 -0.394022  1.323604  0.396881 -1.868242 -0.152760  \n",
        " 9    0.881865  2.110516  0.054782  3.510844  0.186379  0.709308 -0.409238  \n",
        " 10  -2.125828  1.675130 -0.137430  0.488037  0.817900 -0.906300  1.371698  \n",
        " 11   0.283778  0.153505 -0.870782  0.128697 -1.057270 -0.460268  0.930424  \n",
        " 12  -0.755670  1.283407 -0.748315  1.118766 -0.035667 -0.466580  0.525206  \n",
        " 13   0.354591 -0.704720 -0.994755  0.346154 -1.992765 -0.043006  1.363481  \n",
        " 14   0.056618  1.191785 -0.414376  1.003905 -0.273869 -1.568518  0.147835  \n",
        " 15   0.460069 -0.235582  0.908541  1.604067 -0.144376 -0.360808 -1.438284  \n",
        " 16   1.328314  0.417165  0.457554  1.241104 -0.243334  0.143554 -1.314256  \n",
        " 17  -0.488609 -0.661437  2.468581 -1.194021 -1.317828  0.072991  0.580017  \n",
        " 18   1.049466  1.329531  0.851378 -0.872630  0.569834  0.170138 -0.014328  \n",
        " 19   1.793206  0.144106  1.687074  1.116450  1.026708  0.690760 -1.218642  \n",
        " 20   0.187670 -1.265645  1.562305 -0.974613 -1.144446  1.858976 -0.304615  \n",
        " 21   0.648009  1.479887  0.237014 -0.102091 -0.424306  1.105144 -0.792205  \n",
        " 22   0.974942  1.950779 -0.075844 -1.002870 -0.325791 -0.823237 -0.953522  \n",
        " 23  -1.527603 -0.706660  0.701941  1.497003  0.135767 -1.375465  0.360233  \n",
        " 24   0.372183  0.251492  1.196615 -0.812162  0.812581 -0.590464 -0.097109  \n",
        " 25   1.218969  0.994976  0.375506 -0.806442 -0.129328  0.944796 -0.001709  \n",
        " 26  -0.357680  1.151953  0.490046 -1.087264  0.352795  0.227000  0.287900  \n",
        " 27  -0.551473  1.765073 -0.341247 -2.017771  1.163188 -1.083413 -0.466292  \n",
        " 28  -0.134374 -0.593132  1.456376 -1.980204 -1.131998  1.495568  0.937576  \n",
        " 29   0.894516  0.276828 -0.061231  0.576754 -1.328837 -0.590606 -2.520944  \n",
        " ..        ...       ...       ...       ...       ...       ...       ...  \n",
        " 970  0.028337 -1.988826 -0.077648 -0.918449  1.025052 -0.180295 -0.197297  \n",
        " 971 -0.072396 -0.193522 -1.668951 -0.846518 -0.328954 -1.821519  1.059601  \n",
        " 972  1.146515 -0.535107  1.639795 -1.297755  0.657985  0.863315 -0.990740  \n",
        " 973 -0.969484 -0.485421 -1.656809  1.046791 -1.699698  0.708455 -0.156831  \n",
        " 974  0.352147 -0.116751 -0.154777  0.960183  0.395414 -0.061042 -0.322580  \n",
        " 975 -1.216062 -1.094429  2.290265 -0.128994  1.468547  0.114044  0.177380  \n",
        " 976 -1.172977  1.258391  1.052376  0.796369  0.147978 -2.088108  0.608715  \n",
        " 977 -0.812450  0.653344  0.481369  0.710590 -1.171188 -1.003806  0.124105  \n",
        " 978 -0.487519 -0.390283  0.117963  0.377637  0.518965 -0.221915 -0.648131  \n",
        " 979  0.318640  0.972550 -2.528320  1.189220 -0.507969 -0.093103  0.576090  \n",
        " 980  0.514738  0.415845  1.662958 -0.438644  0.738547 -0.911023  0.609567  \n",
        " 981 -0.382158 -0.035499  1.452173 -0.635157 -1.345215 -0.443101  0.377928  \n",
        " 982 -0.540355  0.842463 -0.695370  0.916631  0.544897  0.032422  1.361608  \n",
        " 983 -0.184585  1.064541  0.345514 -0.952976 -0.908573  2.086482 -1.229222  \n",
        " 984  0.882285  0.440914  0.568569  1.774436 -0.690365 -0.088919 -0.078799  \n",
        " 985  2.000569  1.672179 -0.086324  2.108751  0.610264  2.142055 -0.452081  \n",
        " 986  0.728624 -1.659569  0.232187  1.553900  0.576782  0.217307  1.031375  \n",
        " 987 -0.979757 -0.633185 -1.637807  0.558194  0.663296  0.903608  1.204646  \n",
        " 988 -1.841558  0.198859  1.359167 -0.731091 -1.143660  1.205318 -0.058567  \n",
        " 989 -1.051403  1.199599  1.590223  1.407460  0.131064  0.539702  0.463315  \n",
        " 990  0.745798  1.746454 -0.634516 -0.038540 -1.046814  0.375747 -0.899132  \n",
        " 991  0.049980  0.766890  0.012255 -1.300009 -1.902284  0.538790 -1.448589  \n",
        " 992 -0.777510  0.112427  0.905064  0.365634  1.001759  0.830781 -0.570362  \n",
        " 993  1.744678 -0.908464 -1.152979 -0.519524  0.032816 -0.640255  0.919545  \n",
        " 994 -0.467906  0.267300 -0.775554 -0.915739 -0.877088  0.902944 -0.503776  \n",
        " 995  2.032371  0.418168 -0.484227 -0.877188  1.578590 -0.809888  0.328456  \n",
        " 996  0.477274 -0.387270  1.050338 -1.148986 -1.548766  0.354266  0.059252  \n",
        " 997 -0.434422  0.889280  0.608129 -1.123611 -0.241521 -0.333948  0.764316  \n",
        " 998  0.863556 -1.517694  1.218220  0.787357 -1.124006 -0.150231  0.058815  \n",
        " 999  1.044219 -1.045599  1.871140 -0.047166  1.134148  3.001915  0.952727  \n",
        " \n",
        " [1000 rows x 100 columns], 'test': 0       True\n",
        " 1       True\n",
        " 2      False\n",
        " 3       True\n",
        " 4       True\n",
        " 5      False\n",
        " 6      False\n",
        " 7       True\n",
        " 8       True\n",
        " 9       True\n",
        " 10     False\n",
        " 11      True\n",
        " 12      True\n",
        " 13      True\n",
        " 14     False\n",
        " 15     False\n",
        " 16      True\n",
        " 17      True\n",
        " 18      True\n",
        " 19      True\n",
        " 20     False\n",
        " 21     False\n",
        " 22      True\n",
        " 23     False\n",
        " 24     False\n",
        " 25      True\n",
        " 26     False\n",
        " 27     False\n",
        " 28     False\n",
        " 29      True\n",
        "        ...  \n",
        " 970     True\n",
        " 971    False\n",
        " 972     True\n",
        " 973     True\n",
        " 974    False\n",
        " 975    False\n",
        " 976     True\n",
        " 977     True\n",
        " 978     True\n",
        " 979    False\n",
        " 980     True\n",
        " 981    False\n",
        " 982     True\n",
        " 983     True\n",
        " 984     True\n",
        " 985    False\n",
        " 986     True\n",
        " 987     True\n",
        " 988     True\n",
        " 989     True\n",
        " 990    False\n",
        " 991     True\n",
        " 992     True\n",
        " 993     True\n",
        " 994    False\n",
        " 995    False\n",
        " 996    False\n",
        " 997     True\n",
        " 998    False\n",
        " 999     True\n",
        " dtype: bool, 'train': 0      False\n",
        " 1      False\n",
        " 2       True\n",
        " 3      False\n",
        " 4      False\n",
        " 5       True\n",
        " 6       True\n",
        " 7      False\n",
        " 8      False\n",
        " 9      False\n",
        " 10      True\n",
        " 11     False\n",
        " 12     False\n",
        " 13     False\n",
        " 14      True\n",
        " 15      True\n",
        " 16     False\n",
        " 17     False\n",
        " 18     False\n",
        " 19     False\n",
        " 20      True\n",
        " 21      True\n",
        " 22     False\n",
        " 23      True\n",
        " 24      True\n",
        " 25     False\n",
        " 26      True\n",
        " 27      True\n",
        " 28      True\n",
        " 29     False\n",
        "        ...  \n",
        " 970    False\n",
        " 971     True\n",
        " 972    False\n",
        " 973    False\n",
        " 974     True\n",
        " 975     True\n",
        " 976    False\n",
        " 977    False\n",
        " 978    False\n",
        " 979     True\n",
        " 980    False\n",
        " 981     True\n",
        " 982    False\n",
        " 983    False\n",
        " 984    False\n",
        " 985     True\n",
        " 986    False\n",
        " 987    False\n",
        " 988    False\n",
        " 989    False\n",
        " 990     True\n",
        " 991    False\n",
        " 992    False\n",
        " 993    False\n",
        " 994     True\n",
        " 995     True\n",
        " 996     True\n",
        " 997    False\n",
        " 998     True\n",
        " 999    False\n",
        " dtype: bool, 'y': 0      0\n",
        " 1      1\n",
        " 2      0\n",
        " 3      0\n",
        " 4      1\n",
        " 5      0\n",
        " 6      0\n",
        " 7      0\n",
        " 8      0\n",
        " 9      0\n",
        " 10     0\n",
        " 11     0\n",
        " 12     0\n",
        " 13     0\n",
        " 14     0\n",
        " 15     0\n",
        " 16     0\n",
        " 17     1\n",
        " 18     1\n",
        " 19     0\n",
        " 20     1\n",
        " 21     0\n",
        " 22     1\n",
        " 23     0\n",
        " 24     1\n",
        " 25     1\n",
        " 26     1\n",
        " 27     1\n",
        " 28     1\n",
        " 29     0\n",
        "       ..\n",
        " 970    1\n",
        " 971    1\n",
        " 972    1\n",
        " 973    0\n",
        " 974    0\n",
        " 975    0\n",
        " 976    0\n",
        " 977    0\n",
        " 978    0\n",
        " 979    0\n",
        " 980    1\n",
        " 981    1\n",
        " 982    0\n",
        " 983    1\n",
        " 984    0\n",
        " 985    0\n",
        " 986    0\n",
        " 987    0\n",
        " 988    1\n",
        " 989    0\n",
        " 990    0\n",
        " 991    1\n",
        " 992    0\n",
        " 993    1\n",
        " 994    1\n",
        " 995    1\n",
        " 996    1\n",
        " 997    0\n",
        " 998    0\n",
        " 999    0\n",
        " dtype: int64}"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The _result_ is a dictionary containing a standard set of objects that drain uses for machine learning workflows:\n",
      " - `X` is a matrix of features, also called a design matrix,\n",
      " - `y` is a vector of outcomes\n",
      " - `train` is a binary vector indicating the rows of `X` which are in the training set\n",
      " - `test` is a binary vector indicating the rows of `X` which are in the test set"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's add another step to our workflow to construct a random forest estimator:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import drain.model, drain.step\n",
      "estimator = drain.step.Construct('sklearn.ensemble.RandomForestClassifier', n_estimators=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `Construct` step is simply constructs an instance of the specified class with the given arguments:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "estimator.execute()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tConstruct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=1)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
        "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
        "            min_samples_leaf=1, min_samples_split=2,\n",
        "            min_weight_fraction_leaf=0.0, n_estimators=1, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0,\n",
        "            warm_start=False)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we add another step to fit this estimator on our previously generated dataset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fit = drain.model.Fit(inputs=[estimator, data], return_estimator=True, return_feature_importances=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note the special `inputs` argument. This argument is a collection of steps whose results `Fit` takes as input. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fit.execute()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tFit(inputs=[Construct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=1), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t  prefit=False, return_estimator=True, return_feature_importances=True,\n",
        "\t  return_predictions=False)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Fitting with 392 examples, 100 features\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "{'estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
        "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
        "             min_samples_leaf=1, min_samples_split=2,\n",
        "             min_weight_fraction_leaf=0.0, n_estimators=1, n_jobs=1,\n",
        "             oob_score=False, random_state=None, verbose=0,\n",
        "             warm_start=False), 'feature_importances':     feature  importance\n",
        " 38       38    0.152378\n",
        " 96       96    0.111899\n",
        " 11       11    0.061071\n",
        " 79       79    0.046286\n",
        " 84       84    0.044512\n",
        " 48       48    0.041138\n",
        " 82       82    0.037886\n",
        " 53       53    0.037471\n",
        " 18       18    0.034083\n",
        " 26       26    0.032706\n",
        " 76       76    0.030827\n",
        " 0         0    0.029203\n",
        " 22       22    0.028594\n",
        " 34       34    0.026507\n",
        " 99       99    0.026000\n",
        " 78       78    0.025110\n",
        " 64       64    0.020386\n",
        " 37       37    0.020012\n",
        " 77       77    0.018746\n",
        " 6         6    0.018398\n",
        " 89       89    0.018124\n",
        " 23       23    0.017522\n",
        " 59       59    0.016851\n",
        " 39       39    0.015019\n",
        " 42       42    0.014395\n",
        " 27       27    0.009911\n",
        " 29       29    0.009858\n",
        " 58       58    0.009626\n",
        " 74       74    0.009402\n",
        " 73       73    0.008307\n",
        " ..      ...         ...\n",
        " 30       30    0.000000\n",
        " 28       28    0.000000\n",
        " 25       25    0.000000\n",
        " 24       24    0.000000\n",
        " 13       13    0.000000\n",
        " 21       21    0.000000\n",
        " 20       20    0.000000\n",
        " 19       19    0.000000\n",
        " 14       14    0.000000\n",
        " 17       17    0.000000\n",
        " 9         9    0.000000\n",
        " 41       41    0.000000\n",
        " 61       61    0.000000\n",
        " 43       43    0.000000\n",
        " 60       60    0.000000\n",
        " 16       16    0.000000\n",
        " 56       56    0.000000\n",
        " 55       55    0.000000\n",
        " 54       54    0.000000\n",
        " 7         7    0.000000\n",
        " 52       52    0.000000\n",
        " 51       51    0.000000\n",
        " 1         1    0.000000\n",
        " 49       49    0.000000\n",
        " 8         8    0.000000\n",
        " 47       47    0.000000\n",
        " 46       46    0.000000\n",
        " 45       45    0.000000\n",
        " 44       44    0.000000\n",
        " 50       50    0.000000\n",
        " \n",
        " [100 rows x 2 columns]}"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `Fit` step returns the fitted estimator object as well as a dataframe containing the names of features and their importances."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's add one final step to our pipeline to generate predictions on the test set of our classification data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predict = drain.model.Predict(inputs=[fit, data])\n",
      "predict.execute()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tPredict(inputs=[Fit(inputs=[Construct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=1), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t  prefit=False, return_estimator=True, return_feature_importances=True,\n",
        "\t  return_predictions=False), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t    prefit=True, return_estimator=False, return_feature_importances=False,\n",
        "\t    return_predictions=True)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Predicting 608 examples\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "{'y':      true  score\n",
        " 0       0      0\n",
        " 1       1      1\n",
        " 3       0      0\n",
        " 4       1      1\n",
        " 7       0      0\n",
        " 8       0      0\n",
        " 9       0      0\n",
        " 11      0      0\n",
        " 12      0      0\n",
        " 13      0      0\n",
        " 16      0      0\n",
        " 17      1      0\n",
        " 18      1      0\n",
        " 19      0      1\n",
        " 22      1      1\n",
        " 25      1      1\n",
        " 29      0      0\n",
        " 33      0      0\n",
        " 34      0      1\n",
        " 35      0      0\n",
        " 36      0      0\n",
        " 38      1      0\n",
        " 40      0      0\n",
        " 43      1      1\n",
        " 47      0      0\n",
        " 48      1      1\n",
        " 49      1      0\n",
        " 50      0      0\n",
        " 51      0      1\n",
        " 56      1      1\n",
        " ..    ...    ...\n",
        " 946     0      0\n",
        " 948     0      1\n",
        " 954     1      1\n",
        " 957     1      0\n",
        " 958     1      1\n",
        " 959     0      0\n",
        " 960     1      1\n",
        " 961     0      1\n",
        " 963     0      1\n",
        " 964     1      1\n",
        " 969     1      1\n",
        " 970     1      0\n",
        " 972     1      0\n",
        " 973     0      0\n",
        " 976     0      0\n",
        " 977     0      0\n",
        " 978     0      1\n",
        " 980     1      0\n",
        " 982     0      0\n",
        " 983     1      1\n",
        " 984     0      0\n",
        " 986     0      1\n",
        " 987     0      0\n",
        " 988     1      1\n",
        " 989     0      0\n",
        " 991     1      0\n",
        " 992     0      0\n",
        " 993     1      0\n",
        " 997     0      0\n",
        " 999     0      1\n",
        " \n",
        " [608 rows x 2 columns]}"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Predict method returns a dataframe with a `score` column containing the predictions of the estimator and a `true` column containing the true outcomes."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `drain.model` module contains a variety of metrics which can be run directly on the predict object:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "drain.model.auc(predict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "0.63894663894663895"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "drain.model.baseline(predict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "0.48684210526315791"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "drain.model.precision(predict, k=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "0.80000000000000004"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can retrieve the results of any step that has been run through the `get_result` method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predict.get_result()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "{'y':      true  score\n",
        " 0       0      0\n",
        " 1       1      1\n",
        " 3       0      0\n",
        " 4       1      1\n",
        " 7       0      0\n",
        " 8       0      0\n",
        " 9       0      0\n",
        " 11      0      0\n",
        " 12      0      0\n",
        " 13      0      0\n",
        " 16      0      0\n",
        " 17      1      0\n",
        " 18      1      0\n",
        " 19      0      1\n",
        " 22      1      1\n",
        " 25      1      1\n",
        " 29      0      0\n",
        " 33      0      0\n",
        " 34      0      1\n",
        " 35      0      0\n",
        " 36      0      0\n",
        " 38      1      0\n",
        " 40      0      0\n",
        " 43      1      1\n",
        " 47      0      0\n",
        " 48      1      1\n",
        " 49      1      0\n",
        " 50      0      0\n",
        " 51      0      1\n",
        " 56      1      1\n",
        " ..    ...    ...\n",
        " 946     0      0\n",
        " 948     0      1\n",
        " 954     1      1\n",
        " 957     1      0\n",
        " 958     1      1\n",
        " 959     0      0\n",
        " 960     1      1\n",
        " 961     0      1\n",
        " 963     0      1\n",
        " 964     1      1\n",
        " 969     1      1\n",
        " 970     1      0\n",
        " 972     1      0\n",
        " 973     0      0\n",
        " 976     0      0\n",
        " 977     0      0\n",
        " 978     0      1\n",
        " 980     1      0\n",
        " 982     0      0\n",
        " 983     1      1\n",
        " 984     0      0\n",
        " 986     0      1\n",
        " 987     0      0\n",
        " 988     1      1\n",
        " 989     0      0\n",
        " 991     1      0\n",
        " 992     0      0\n",
        " 993     1      0\n",
        " 997     0      0\n",
        " 999     0      1\n",
        " \n",
        " [608 rows x 2 columns]}"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## More on workflow execution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's redefine the above workflow using a function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def prediction_workflow():\n",
      "    # generate the data including a training and test split\n",
      "    data = drain.data.ClassificationData(target=True, n_samples=1000, n_features=100)\n",
      "    # construct a random forest estimator\n",
      "    estimator = drain.step.Construct('sklearn.ensemble.RandomForestClassifier', n_estimators=1)\n",
      "    # fit the estimator\n",
      "    fit = drain.model.Fit(inputs=[estimator, data], return_estimator=True, return_feature_importances=True)\n",
      "    # make predictions\n",
      "    return drain.model.Predict(inputs=[fit, data])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predict2 = prediction_workflow()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that step execution is recursive, that is the `execute` method will ensure that all inputs, and inputs of inputs, etc. have been run before running the given step:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predict2.execute()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tConstruct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=1)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tClassificationData(n_features=100, n_samples=1000)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tFit(inputs=[Construct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=1), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t  prefit=False, return_estimator=True, return_feature_importances=True,\n",
        "\t  return_predictions=False)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Fitting with 396 examples, 100 features\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tPredict(inputs=[Fit(inputs=[Construct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=1), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t  prefit=False, return_estimator=True, return_feature_importances=True,\n",
        "\t  return_predictions=False), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t    prefit=True, return_estimator=False, return_feature_importances=False,\n",
        "\t    return_predictions=True)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Predicting 604 examples\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "{'y':      true  score\n",
        " 0       0      1\n",
        " 2       0      1\n",
        " 3       1      1\n",
        " 4       0      0\n",
        " 8       0      1\n",
        " 9       0      1\n",
        " 12      1      1\n",
        " 13      0      0\n",
        " 14      1      0\n",
        " 16      0      0\n",
        " 21      1      0\n",
        " 22      1      1\n",
        " 23      1      0\n",
        " 24      1      0\n",
        " 25      0      0\n",
        " 27      0      1\n",
        " 30      1      1\n",
        " 31      1      0\n",
        " 33      1      0\n",
        " 34      1      1\n",
        " 35      0      0\n",
        " 36      1      1\n",
        " 37      1      0\n",
        " 38      1      0\n",
        " 43      1      0\n",
        " 44      1      0\n",
        " 45      0      1\n",
        " 46      0      1\n",
        " 48      0      1\n",
        " 49      0      0\n",
        " ..    ...    ...\n",
        " 962     1      1\n",
        " 963     1      0\n",
        " 964     0      0\n",
        " 967     0      1\n",
        " 968     1      0\n",
        " 969     0      0\n",
        " 970     1      1\n",
        " 971     1      1\n",
        " 972     0      0\n",
        " 973     1      0\n",
        " 974     0      0\n",
        " 975     1      0\n",
        " 976     1      1\n",
        " 977     0      0\n",
        " 978     1      1\n",
        " 979     0      1\n",
        " 983     1      0\n",
        " 984     1      0\n",
        " 985     1      0\n",
        " 986     0      1\n",
        " 987     0      0\n",
        " 988     0      1\n",
        " 989     1      1\n",
        " 992     0      1\n",
        " 993     0      0\n",
        " 995     0      0\n",
        " 996     0      0\n",
        " 997     0      0\n",
        " 998     0      1\n",
        " 999     1      1\n",
        " \n",
        " [604 rows x 2 columns]}"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The steps of a workflow form a network (a directed acyclic graph or DAG, to be precise)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## A more complicated workflow"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In practice we want to train many models on a given dataset. Let's define a workflow that searches over the number of trees in the random forest model:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def n_estimator_search():\n",
      "    data = drain.data.ClassificationData(target=True, n_samples=1000, n_features=100)\n",
      "    \n",
      "    predict = []\n",
      "    for n_estimators in range(1, 4):\n",
      "        estimator = drain.step.Construct('sklearn.ensemble.RandomForestClassifier', n_estimators=n_estimators, name = 'estimator')\n",
      "        fit = drain.model.Fit(inputs=[estimator, data], return_estimator=True, return_feature_importances=True)\n",
      "        predict.append(drain.model.Predict(inputs=[fit, data]))\n",
      "        \n",
      "    return predict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions = n_estimator_search()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for p in predictions:\n",
      "    p.execute()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tConstruct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=1)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tClassificationData(n_features=100, n_samples=1000)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tFit(inputs=[Construct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=1), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t  prefit=False, return_estimator=True, return_feature_importances=True,\n",
        "\t  return_predictions=False)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Fitting with 400 examples, 100 features\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tPredict(inputs=[Fit(inputs=[Construct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=1), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t  prefit=False, return_estimator=True, return_feature_importances=True,\n",
        "\t  return_predictions=False), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t    prefit=True, return_estimator=False, return_feature_importances=False,\n",
        "\t    return_predictions=True)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Predicting 600 examples\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tConstruct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=2)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tFit(inputs=[Construct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=2), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t  prefit=False, return_estimator=True, return_feature_importances=True,\n",
        "\t  return_predictions=False)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Fitting with 400 examples, 100 features\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tPredict(inputs=[Fit(inputs=[Construct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=2), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t  prefit=False, return_estimator=True, return_feature_importances=True,\n",
        "\t  return_predictions=False), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t    prefit=True, return_estimator=False, return_feature_importances=False,\n",
        "\t    return_predictions=True)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Predicting 600 examples\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tConstruct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=3)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tFit(inputs=[Construct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=3), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t  prefit=False, return_estimator=True, return_feature_importances=True,\n",
        "\t  return_predictions=False)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Fitting with 400 examples, 100 features\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tPredict(inputs=[Fit(inputs=[Construct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=3), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t  prefit=False, return_estimator=True, return_feature_importances=True,\n",
        "\t  return_predictions=False), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t    prefit=True, return_estimator=False, return_feature_importances=False,\n",
        "\t    return_predictions=True)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Predicting 600 examples\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that the ClassificationData step was only run once."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Drain provides some additional utilities for model exploration in the `drain.explore` module:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from drain import explore\n",
      "df = explore.to_dataframe(predictions)\n",
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>n_estimators</th>\n",
        "      <th>step</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>1</td>\n",
        "      <td>Predict(inputs=[Fit(inputs=[Construct(__class_...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>2</td>\n",
        "      <td>Predict(inputs=[Fit(inputs=[Construct(__class_...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>3</td>\n",
        "      <td>Predict(inputs=[Fit(inputs=[Construct(__class_...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "   n_estimators                                               step\n",
        "0             1  Predict(inputs=[Fit(inputs=[Construct(__class_...\n",
        "1             2  Predict(inputs=[Fit(inputs=[Construct(__class_...\n",
        "2             3  Predict(inputs=[Fit(inputs=[Construct(__class_..."
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from drain import model\n",
      "explore.apply(df, model.auc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "n_estimators\n",
        "1    0.750700\n",
        "2    0.809657\n",
        "3    0.778523\n",
        "Name: step, dtype: float64"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "explore.apply(df, model.precision_series).plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "<matplotlib.axes._subplots.AxesSubplot at 0x7fe129261dd0>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7fe1292614d0>"
       ]
      }
     ],
     "prompt_number": 21
    }
   ],
   "metadata": {}
  }
 ]
}