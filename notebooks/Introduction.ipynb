{
 "metadata": {
  "name": "",
  "signature": "sha256:c6f7c5bf6e6fa66341a348027022c36f104bd95b20a0534b03b0e74eedd260d9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Enable logging\n",
      "import logging\n",
      "logger = logging.getLogger()\n",
      "logger.setLevel(logging.INFO)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## A simple prediction workflow"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Drain workflows consist of `drain.step.Step` objects. Take for example the `drain.data.ClassificationData` step:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import drain.data\n",
      "data = drain.data.ClassificationData(target=True, n_samples=1000, n_features=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This step calls the `sklearn.datasets.make_classification` method to generate a dataset with a binary outcome. We can run the step by step by calling its `execute` method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.execute()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tClassificationData(n_features=100, n_samples=1000)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 101,
       "text": [
        "{'X':            0         1         2         3         4         5         6   \\\n",
        " 0   -0.867318 -1.932298 -0.062109  0.207251  0.541636  0.467962  1.068307   \n",
        " 1    0.229266  0.108010  0.261246  0.983346  0.325750 -1.513282  1.724452   \n",
        " 2    0.523565  0.850771 -1.342609 -0.833464 -0.459670  0.288330 -0.306867   \n",
        " 3   -0.523586  0.800911  0.211946 -0.693518  1.435917 -1.135968 -0.130478   \n",
        " 4    0.562866 -0.467994  0.063342  0.252156  0.796485 -0.078995  1.053827   \n",
        " 5    0.281155  0.287670 -0.099493 -1.609496  1.276864  0.616879 -0.092994   \n",
        " 6    0.078634  0.922847 -0.018837 -0.501806 -0.542494  1.848380  0.411128   \n",
        " 7   -0.612060 -0.967827  1.293210 -0.962393 -0.314047  1.629515 -0.319694   \n",
        " 8    1.308851  0.952589 -0.472525  0.525457  1.753440 -0.353194  0.644502   \n",
        " 9    0.820878 -0.071178  0.747465 -1.039198  0.047651 -0.182658  0.184964   \n",
        " 10  -0.190090 -1.228267 -1.104390  0.673559 -1.403298  0.004430  1.275510   \n",
        " 11   0.357722  0.600313  0.264324  0.903777  0.397777  0.177900 -1.017898   \n",
        " 12   0.150678  0.228863 -2.143536  0.885623  1.136905 -1.618050 -0.081665   \n",
        " 13   2.570297 -0.762131 -0.355376 -0.448079 -0.736529 -0.963387  1.025413   \n",
        " 14  -0.857468  1.475200 -1.893905  0.486714  0.904920  0.731136  0.382504   \n",
        " 15  -1.043272  0.705718  0.480902 -1.294697  0.474972 -0.574334  1.226544   \n",
        " 16   2.812598 -1.467111 -1.965126  0.828098  1.310748 -1.744586  0.643317   \n",
        " 17  -0.189747  1.832682 -0.356941  0.132931 -0.167770  1.328772 -2.070746   \n",
        " 18   0.402535 -0.084190 -0.289527  0.026763 -0.492567  0.376925 -2.827349   \n",
        " 19  -0.490687  1.108500  0.986563 -1.955056 -2.142298  0.364117  1.180585   \n",
        " 20   0.088171 -0.495006  0.857899 -0.017089  1.575175  0.951070  0.321825   \n",
        " 21   0.302027 -0.423001  0.031775  1.238844 -1.375737 -1.155576 -1.559067   \n",
        " 22  -0.479686  2.527390  1.274495 -1.273610 -0.716569 -1.436579 -0.041779   \n",
        " 23   1.431120 -1.973113  0.946162 -0.178812  0.296872 -1.553677  0.641109   \n",
        " 24   1.729679 -0.973248  0.924567 -0.775467 -1.407821 -0.850979 -1.891497   \n",
        " 25   1.034290  1.560378 -1.638712  0.390836  1.061833  0.115498 -0.738501   \n",
        " 26   0.040414 -1.554381  0.428000 -0.217443  0.291981 -0.023090  0.692918   \n",
        " 27  -0.320768 -1.277957 -0.083818 -0.316054  0.790790  0.022286  0.228901   \n",
        " 28   0.577891  0.758458 -0.086912  0.595266 -0.888615 -0.169150 -0.106773   \n",
        " 29  -0.346509 -0.110448  0.130369 -1.023304 -0.985951  2.097992 -0.023443   \n",
        " ..        ...       ...       ...       ...       ...       ...       ...   \n",
        " 970  1.838004  2.115886 -1.105339 -0.375462 -1.484924  0.046607 -0.884646   \n",
        " 971 -0.583234  0.247452  1.365085  0.327588 -0.957024  0.318067 -0.895297   \n",
        " 972 -0.902621  1.076926 -0.360961 -0.765008  0.787912  1.783385 -0.082593   \n",
        " 973 -0.022903 -1.131114  0.870522 -0.681507 -2.169952 -0.060406  0.213070   \n",
        " 974 -1.261524  0.091912  0.429961  0.154852  0.277600 -1.044326 -0.422343   \n",
        " 975 -1.462071 -0.838400 -0.498475  1.001278 -0.913490  0.705677 -1.759663   \n",
        " 976 -0.818214  0.823602 -1.515878  0.336041  0.087915  1.174616 -0.531843   \n",
        " 977 -0.180612  0.264543 -1.099617 -0.537086  0.685457  0.377757 -0.169762   \n",
        " 978  0.852675 -0.185862 -1.984781 -0.184501 -0.928917 -1.051376  0.195396   \n",
        " 979 -1.180298  0.040253 -1.375469  1.022991 -0.089746 -0.296222 -0.548275   \n",
        " 980 -0.905520  0.265164  0.436850  0.216268  0.917544  1.213516  0.216255   \n",
        " 981 -0.326766 -0.428696  1.654056 -1.298546  1.438903 -1.418605  1.041483   \n",
        " 982 -0.304500 -0.792995 -0.149941 -0.811240 -0.236789  1.130087 -0.941212   \n",
        " 983 -1.652531 -0.229587 -0.608002  0.285671  0.646384 -0.678384  0.723465   \n",
        " 984 -0.783771 -1.826262  1.199327 -1.722077  0.824115  1.373310  0.923175   \n",
        " 985 -0.736100  0.340770 -0.328341  0.081981  0.302869 -0.857137 -0.842061   \n",
        " 986 -0.706931 -0.583087 -0.036457  0.746399  0.138523  0.774832 -0.245161   \n",
        " 987  0.395218  1.017682  1.901217 -1.258835 -1.162511 -0.895790 -1.658225   \n",
        " 988 -0.539455  1.482509 -0.065641 -0.068771  0.210537  0.430073  0.993113   \n",
        " 989  0.684456 -0.773519 -0.994508 -0.252577  0.700504  0.008171  0.414967   \n",
        " 990  0.061052  0.845826  0.383434 -0.715277  0.041372  0.074391 -0.031647   \n",
        " 991 -0.349765  0.548413 -0.551167  2.333240 -0.444145 -0.013029  1.136950   \n",
        " 992  1.406306  0.412304 -0.034733  2.163612  0.744217  0.032273  0.318003   \n",
        " 993  0.000017 -1.245351  0.234671  0.154867  1.477296 -0.548634  0.110575   \n",
        " 994 -0.765700 -0.787693 -0.799123 -1.376034 -0.944334  0.205618 -1.426458   \n",
        " 995  0.877078  0.050325  0.959193 -0.579918  1.338941  0.907304 -0.484443   \n",
        " 996  0.577718 -1.362963  0.369481 -1.088320 -0.300301  0.044036  0.214781   \n",
        " 997  1.077275  1.356541  0.434586 -0.104331 -0.088099 -0.656395  0.427487   \n",
        " 998  0.374767 -0.521526 -1.165936 -0.266864 -0.129365 -0.643492  0.749603   \n",
        " 999 -1.098489  0.565208  0.779691  0.377928  1.487821 -2.903812  0.017491   \n",
        " \n",
        "            7         8         9     ...           90        91        92  \\\n",
        " 0   -0.174381 -0.013960 -0.667778    ...    -0.045748  2.714027 -0.727964   \n",
        " 1   -1.135703  0.622287  1.066216    ...     0.396365 -1.262410 -0.373326   \n",
        " 2    0.936901  1.429171 -0.997893    ...     0.273921 -0.564184  0.089425   \n",
        " 3    0.169684 -2.418202 -0.227249    ...    -1.406327 -1.346801 -0.163205   \n",
        " 4   -0.155990  0.552022 -0.434168    ...    -0.587973  0.489473 -1.958503   \n",
        " 5    0.583743 -0.312123 -0.369398    ...     0.769472  0.651301  0.831952   \n",
        " 6    0.868687  1.423100 -0.433574    ...     0.282389  0.240563 -0.093193   \n",
        " 7    0.816095  0.954611 -0.337443    ...    -0.783374  1.527858  0.756698   \n",
        " 8    1.854802 -0.420459 -0.977596    ...    -1.576799 -0.895332  0.252315   \n",
        " 9    0.737525  0.075270 -0.489394    ...    -0.688865 -0.287770 -0.439881   \n",
        " 10  -1.576944 -1.024794  1.317469    ...    -0.125024 -0.304208 -0.311639   \n",
        " 11   2.495841 -0.183567 -1.725514    ...    -1.452855  1.162043 -1.670102   \n",
        " 12  -0.860218 -0.488317  0.833293    ...     0.599924  1.900523 -0.787777   \n",
        " 13   1.412322 -1.059597 -0.650065    ...    -0.843563  0.181632  1.481139   \n",
        " 14  -0.322527  0.501359  0.352579    ...    -0.072220  0.073155 -1.598106   \n",
        " 15   0.872194  0.042347 -0.352816    ...    -1.683747 -0.246860  0.646183   \n",
        " 16  -0.442473 -0.218459 -0.627824    ...     0.559224 -0.358248 -2.727026   \n",
        " 17  -0.641611 -0.802092  0.454425    ...    -0.059564  1.296725  0.364939   \n",
        " 18  -1.784446 -0.821560  1.807847    ...    -0.167313  0.632407 -0.733142   \n",
        " 19  -1.545747 -0.769900  1.514515    ...     1.540276  0.811732 -0.528360   \n",
        " 20   0.278576  0.021167 -0.171003    ...    -1.871340 -0.828417 -0.212000   \n",
        " 21   0.047451  0.750524 -0.029089    ...    -0.158566 -1.027496  1.023658   \n",
        " 22   0.528625  0.081560 -0.166738    ...    -1.161997  0.116608 -0.420740   \n",
        " 23   0.695213 -0.706375 -0.751531    ...     0.409263  0.372815  0.407009   \n",
        " 24  -1.505565 -0.732491  1.533169    ...     0.326923 -0.856435 -0.723910   \n",
        " 25   1.512470  0.377964 -0.686663    ...     0.425438  0.951908 -0.461547   \n",
        " 26   0.737261  0.764731 -1.008717    ...    -0.084232 -0.800257  0.930747   \n",
        " 27   2.347517  0.107012 -1.952388    ...    -1.074484  1.649066  0.248296   \n",
        " 28   0.588209 -1.995577 -0.115316    ...     0.316999  1.505850 -0.512867   \n",
        " 29  -0.019313 -1.172135 -0.062088    ...    -0.950564  1.937529  0.072980   \n",
        " ..        ...       ...       ...    ...          ...       ...       ...   \n",
        " 970  0.414938 -0.090677 -0.891485    ...     1.048269  0.345343 -0.193875   \n",
        " 971  0.661435  2.267100 -0.506601    ...    -0.498397 -2.768551 -0.722129   \n",
        " 972 -0.638874 -1.601398  0.752286    ...    -0.050766 -0.399263  0.535790   \n",
        " 973  0.067408  0.318408 -0.018800    ...     1.137587 -0.121831  0.649179   \n",
        " 974 -1.505895  1.002985  1.689121    ...    -0.035393  0.806643  0.486352   \n",
        " 975 -1.034004  0.759460  1.069218    ...     1.489657  0.224469  0.172839   \n",
        " 976 -0.889485 -1.175391  0.325253    ...    -1.929961  0.474318 -0.022910   \n",
        " 977 -1.514713 -0.398851  0.848816    ...    -0.287230  1.605544 -0.206093   \n",
        " 978 -0.716438  1.058763  0.335012    ...    -1.393560  0.042033  0.752758   \n",
        " 979 -0.255863 -1.510956  0.046720    ...    -1.119738 -0.024547  0.166681   \n",
        " 980  0.444598  0.992019 -0.245134    ...    -0.783915  0.056049  0.640868   \n",
        " 981 -0.799739 -0.750995  1.027952    ...     0.346006  0.068221  0.429988   \n",
        " 982 -1.810303 -0.068514  1.598084    ...    -0.093116 -1.129709 -0.462331   \n",
        " 983 -1.056831 -0.097139  1.268233    ...    -0.221575  2.573447 -0.356625   \n",
        " 984 -0.117294 -1.426534  0.139671    ...    -0.249183  0.725667 -0.209362   \n",
        " 985 -0.678402 -0.056499  0.683324    ...    -0.580212  0.266261  0.729212   \n",
        " 986 -0.214306  0.524083 -0.098134    ...    -0.283894 -1.383985  0.869072   \n",
        " 987  0.483197  2.259193 -0.272489    ...     0.599719  0.846683 -1.170143   \n",
        " 988  1.454683  1.901002 -0.682928    ...    -0.720534  0.711071  1.656687   \n",
        " 989  1.102447 -0.759540 -0.662968    ...     1.146631 -0.198852 -0.293990   \n",
        " 990 -1.415019  0.389591  1.455837    ...    -0.640720  0.346065  0.238454   \n",
        " 991  1.245400 -0.442054 -0.673878    ...     1.280351  0.055060  2.120457   \n",
        " 992 -0.877499  0.062364  0.820316    ...    -2.027145 -2.546442  0.987567   \n",
        " 993  0.828263  0.226564 -0.892336    ...    -1.526852  1.520043  0.940375   \n",
        " 994 -1.327339 -0.023700  0.778728    ...    -1.324712  0.727807 -0.672561   \n",
        " 995  2.005233  2.021374 -1.766313    ...     1.081780  0.169647  1.628854   \n",
        " 996 -0.961567  0.390564  0.444878    ...     1.837345  0.718201  1.531637   \n",
        " 997  0.655821  0.487859 -0.329364    ...    -2.374853 -0.874436 -2.358008   \n",
        " 998  2.679980  0.059255 -2.801521    ...    -0.972069 -1.434753  0.059299   \n",
        " 999  1.878178  0.529675 -0.806007    ...    -0.349328 -0.648591 -0.522913   \n",
        " \n",
        "            93        94        95        96        97        98        99  \n",
        " 0    1.584106  1.595656  2.258949  2.051888 -0.091176  0.024863 -0.851158  \n",
        " 1   -0.689294 -1.365618 -1.367475 -1.406261 -2.070213 -0.860168 -1.533717  \n",
        " 2    0.538490  0.157195  0.240378 -0.257475 -1.656919  0.686376 -0.169409  \n",
        " 3   -0.273872 -0.313731 -0.145887 -1.127802 -1.569073  1.155824 -1.077288  \n",
        " 4    1.206282  0.163722  0.181875  0.237810 -0.007565  0.725721 -1.492935  \n",
        " 5    0.018915 -1.002526 -0.015625  0.236920  0.286666 -0.894099  1.271696  \n",
        " 6   -2.219787  0.467481 -0.106165  0.150798 -0.374630 -0.199798 -1.542461  \n",
        " 7    0.046820  0.244625  0.127151  0.125094 -0.009339  1.981692  1.341507  \n",
        " 8   -0.340653 -0.357806  1.695658  0.431307 -0.144426  0.470594 -1.237999  \n",
        " 9    1.496184  0.462779 -1.967951  0.698897  0.590738 -0.362434  0.586049  \n",
        " 10  -0.230280  0.670626  1.287470  0.391441 -0.175754  0.779766 -0.807152  \n",
        " 11   0.588611 -0.432696  0.981584  0.846588 -0.276922 -1.046196 -0.374442  \n",
        " 12  -2.294460  0.243372  0.154967  0.316749  2.042092  0.206167  0.343622  \n",
        " 13  -0.442432 -0.527039  0.655579 -0.418421  1.069933 -0.305012 -0.251234  \n",
        " 14   0.120564 -1.022515  1.690062 -0.565581  0.801562  0.645782 -0.997664  \n",
        " 15  -2.334850 -0.641958  0.646722  0.441268 -0.376369  0.394047 -1.009763  \n",
        " 16  -0.198893 -1.400134 -0.756983  0.308856 -0.012936  1.022918 -0.009432  \n",
        " 17   0.580402 -0.288519 -0.126593 -0.479770 -1.215712  0.226662  1.363230  \n",
        " 18  -0.981442  0.920799  1.676177  0.782886 -1.067466  0.714235 -1.186298  \n",
        " 19  -1.631826  0.784792  0.431053 -0.123537 -0.381727 -0.181925 -1.931638  \n",
        " 20  -1.241014 -1.305835 -0.693481 -0.973571 -0.143746  0.874048  0.256007  \n",
        " 21   0.815678 -0.403289 -0.783589 -0.409930  0.322115  1.238060  1.257243  \n",
        " 22  -0.122279 -0.324643  0.843622  0.606336 -0.808471 -0.525431  0.089994  \n",
        " 23   0.481485 -0.419302  0.683488 -0.358628  0.593013 -1.497164  1.253020  \n",
        " 24   0.334717  0.152790  0.899275  1.610202  0.658701 -0.027029 -3.026060  \n",
        " 25  -0.185849 -0.756781 -0.206759  0.224855 -0.145004  1.472714  1.349682  \n",
        " 26   0.384132 -1.010518  1.288992  0.981592  0.542976  1.625738 -1.045559  \n",
        " 27   0.721286  0.344765  0.260693 -0.183068  0.955528 -0.873550 -1.046901  \n",
        " 28   0.434840 -1.274769 -0.196902 -1.485260  0.337522 -0.621808  1.325995  \n",
        " 29  -0.256713 -0.249423  0.196127  1.025479 -1.734797 -1.106285 -0.440753  \n",
        " ..        ...       ...       ...       ...       ...       ...       ...  \n",
        " 970  1.319006  0.154670  0.729594 -1.053662  0.128450 -0.174522 -1.389320  \n",
        " 971 -1.883961 -1.918353  1.599644 -0.476839  0.391382 -0.275388 -0.629069  \n",
        " 972  0.778147 -0.317800 -0.263469  0.773797  0.435039  0.145333 -0.263405  \n",
        " 973  0.462773 -0.413033  1.362915 -0.636664 -0.975417  0.103519 -0.922926  \n",
        " 974 -0.965322  0.477674  0.524933 -0.859073 -0.070924  1.610944  0.104979  \n",
        " 975 -0.484584 -0.306113  0.251197  0.415986 -1.811325  0.489787 -1.192467  \n",
        " 976 -0.099295 -0.708038  0.264919  1.010519  0.553009 -0.682606 -0.266279  \n",
        " 977 -0.192013 -0.411277  0.661102 -0.850462  1.104311 -1.283440 -0.387069  \n",
        " 978 -0.742312 -0.019510 -1.630855  1.894677 -0.352073 -0.471117  0.070804  \n",
        " 979 -0.458810  0.072983  2.986066 -2.146556 -1.472569 -0.896920 -0.560406  \n",
        " 980 -0.068115  0.732559  0.357183  0.365557 -1.193552  0.915272  1.233861  \n",
        " 981  0.252127  1.017462  0.754732  1.296118  0.712162  1.243084 -0.399264  \n",
        " 982  1.061330 -0.712018 -0.385229  0.973829 -1.337780  0.464174 -1.448815  \n",
        " 983 -1.730590  1.013685 -1.293021 -2.147801 -0.012963 -0.371457  0.021874  \n",
        " 984 -0.619980 -0.401112 -1.821674 -0.793546 -0.441519  0.822273  0.911532  \n",
        " 985 -0.040980 -0.264246 -0.565495 -1.018335 -0.230020 -1.886073  1.977774  \n",
        " 986 -0.839238  0.887655 -1.248613 -0.125125 -1.670862  0.234697  0.960455  \n",
        " 987 -1.473245  0.376996 -1.263843  0.072898  0.618190  0.638274  0.729670  \n",
        " 988  0.681164 -0.407332 -1.517731  0.596867 -0.237261  1.355768  1.480880  \n",
        " 989 -1.843331 -1.030027 -2.639369 -0.781018  0.436032 -0.157211 -0.680693  \n",
        " 990 -2.833817 -0.376900 -0.056694  1.440601 -0.555095  0.810627 -0.085663  \n",
        " 991  1.216778  2.275265  0.408672  0.763282 -0.292404  0.990283 -1.424703  \n",
        " 992 -0.273836 -1.672138  0.741561 -1.504505 -0.108005  0.732950 -1.263195  \n",
        " 993 -1.120891  0.463297  0.652165 -0.363990 -0.178904 -1.056308  0.799826  \n",
        " 994 -1.352426 -0.217785 -0.173397 -0.169827  1.173720 -1.460458  0.316798  \n",
        " 995 -0.001528 -1.082915  0.686401 -0.222245 -0.460431 -1.325079 -1.971488  \n",
        " 996 -0.057281  0.005414 -1.206929 -0.859392 -0.209440  0.005518 -2.955395  \n",
        " 997  1.331511 -0.281803  1.177743  0.137287 -0.361184  0.854658  1.046186  \n",
        " 998  0.629341  0.322522 -1.736172 -1.225950 -0.505139 -1.025115 -0.569590  \n",
        " 999 -0.987173  1.477178  0.265931 -0.813367  1.148914 -0.265859 -2.350401  \n",
        " \n",
        " [1000 rows x 100 columns], 'test': 0       True\n",
        " 1      False\n",
        " 2      False\n",
        " 3      False\n",
        " 4       True\n",
        " 5      False\n",
        " 6       True\n",
        " 7      False\n",
        " 8      False\n",
        " 9       True\n",
        " 10     False\n",
        " 11     False\n",
        " 12      True\n",
        " 13      True\n",
        " 14      True\n",
        " 15     False\n",
        " 16      True\n",
        " 17      True\n",
        " 18     False\n",
        " 19     False\n",
        " 20      True\n",
        " 21      True\n",
        " 22      True\n",
        " 23     False\n",
        " 24      True\n",
        " 25      True\n",
        " 26     False\n",
        " 27      True\n",
        " 28     False\n",
        " 29      True\n",
        "        ...  \n",
        " 970     True\n",
        " 971    False\n",
        " 972     True\n",
        " 973     True\n",
        " 974     True\n",
        " 975     True\n",
        " 976    False\n",
        " 977     True\n",
        " 978    False\n",
        " 979    False\n",
        " 980     True\n",
        " 981    False\n",
        " 982     True\n",
        " 983     True\n",
        " 984     True\n",
        " 985    False\n",
        " 986     True\n",
        " 987    False\n",
        " 988    False\n",
        " 989    False\n",
        " 990     True\n",
        " 991    False\n",
        " 992    False\n",
        " 993     True\n",
        " 994     True\n",
        " 995     True\n",
        " 996    False\n",
        " 997    False\n",
        " 998     True\n",
        " 999    False\n",
        " dtype: bool, 'train': 0      False\n",
        " 1       True\n",
        " 2       True\n",
        " 3       True\n",
        " 4      False\n",
        " 5       True\n",
        " 6      False\n",
        " 7       True\n",
        " 8       True\n",
        " 9      False\n",
        " 10      True\n",
        " 11      True\n",
        " 12     False\n",
        " 13     False\n",
        " 14     False\n",
        " 15      True\n",
        " 16     False\n",
        " 17     False\n",
        " 18      True\n",
        " 19      True\n",
        " 20     False\n",
        " 21     False\n",
        " 22     False\n",
        " 23      True\n",
        " 24     False\n",
        " 25     False\n",
        " 26      True\n",
        " 27     False\n",
        " 28      True\n",
        " 29     False\n",
        "        ...  \n",
        " 970    False\n",
        " 971     True\n",
        " 972    False\n",
        " 973    False\n",
        " 974    False\n",
        " 975    False\n",
        " 976     True\n",
        " 977    False\n",
        " 978     True\n",
        " 979     True\n",
        " 980    False\n",
        " 981     True\n",
        " 982    False\n",
        " 983    False\n",
        " 984    False\n",
        " 985     True\n",
        " 986    False\n",
        " 987     True\n",
        " 988     True\n",
        " 989     True\n",
        " 990    False\n",
        " 991     True\n",
        " 992     True\n",
        " 993    False\n",
        " 994    False\n",
        " 995    False\n",
        " 996     True\n",
        " 997     True\n",
        " 998    False\n",
        " 999     True\n",
        " dtype: bool, 'y': 0      1\n",
        " 1      0\n",
        " 2      1\n",
        " 3      1\n",
        " 4      0\n",
        " 5      1\n",
        " 6      1\n",
        " 7      1\n",
        " 8      1\n",
        " 9      1\n",
        " 10     0\n",
        " 11     1\n",
        " 12     0\n",
        " 13     1\n",
        " 14     0\n",
        " 15     1\n",
        " 16     1\n",
        " 17     0\n",
        " 18     0\n",
        " 19     0\n",
        " 20     1\n",
        " 21     0\n",
        " 22     1\n",
        " 23     0\n",
        " 24     0\n",
        " 25     1\n",
        " 26     1\n",
        " 27     1\n",
        " 28     1\n",
        " 29     0\n",
        "       ..\n",
        " 970    1\n",
        " 971    1\n",
        " 972    0\n",
        " 973    1\n",
        " 974    0\n",
        " 975    0\n",
        " 976    0\n",
        " 977    0\n",
        " 978    1\n",
        " 979    1\n",
        " 980    1\n",
        " 981    0\n",
        " 982    0\n",
        " 983    0\n",
        " 984    0\n",
        " 985    0\n",
        " 986    1\n",
        " 987    1\n",
        " 988    1\n",
        " 989    1\n",
        " 990    0\n",
        " 991    1\n",
        " 992    0\n",
        " 993    1\n",
        " 994    0\n",
        " 995    1\n",
        " 996    0\n",
        " 997    1\n",
        " 998    1\n",
        " 999    1\n",
        " dtype: int64}"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The _result_ is a dictionary containing a standard set of objects that drain uses for machine learning workflows:\n",
      " - `X` is a matrix of features, also called a design matrix,\n",
      " - `y` is a vector of outcomes\n",
      " - `train` is a binary vector indicating the rows of `X` which are in the training set\n",
      " - `test` is a binary vector indicating the rows of `X` which are in the test set"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's add another step to our workflow to construct a random forest estimator:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import drain.model, drain.step\n",
      "estimator = drain.step.Construct('sklearn.ensemble.RandomForestClassifier', n_estimators=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `Construct` step is simply constructs an instance of the specified class with the given arguments:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "estimator.execute()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tConstruct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=1)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 103,
       "text": [
        "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
        "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
        "            min_samples_leaf=1, min_samples_split=2,\n",
        "            min_weight_fraction_leaf=0.0, n_estimators=1, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0,\n",
        "            warm_start=False)"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we add another step to fit this estimator on our previously generated dataset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fit = drain.model.Fit(inputs=[estimator, data], return_estimator=True, return_feature_importances=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note the special `inputs` argument. This argument is a collection of steps whose results `Fit` takes as input. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fit.execute()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tFit(inputs=[Construct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=1), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t  prefit=False, return_estimator=True, return_feature_importances=True,\n",
        "\t  return_predictions=False)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Fitting with 407 examples, 100 features\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 105,
       "text": [
        "{'estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
        "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
        "             min_samples_leaf=1, min_samples_split=2,\n",
        "             min_weight_fraction_leaf=0.0, n_estimators=1, n_jobs=1,\n",
        "             oob_score=False, random_state=None, verbose=0,\n",
        "             warm_start=False), 'feature_importances':     feature  importance\n",
        " 7         7    0.422487\n",
        " 9         9    0.096678\n",
        " 34       34    0.045342\n",
        " 52       52    0.042223\n",
        " 31       31    0.030508\n",
        " 27       27    0.028017\n",
        " 28       28    0.026790\n",
        " 51       51    0.026078\n",
        " 65       65    0.024441\n",
        " 48       48    0.023495\n",
        " 85       85    0.022820\n",
        " 2         2    0.022064\n",
        " 30       30    0.018269\n",
        " 16       16    0.017048\n",
        " 19       19    0.016247\n",
        " 89       89    0.014893\n",
        " 59       59    0.013238\n",
        " 69       69    0.011272\n",
        " 67       67    0.009547\n",
        " 95       95    0.009547\n",
        " 26       26    0.009532\n",
        " 57       57    0.009477\n",
        " 79       79    0.009345\n",
        " 88       88    0.009283\n",
        " 32       32    0.009026\n",
        " 1         1    0.008798\n",
        " 60       60    0.008147\n",
        " 25       25    0.007522\n",
        " 71       71    0.006619\n",
        " 24       24    0.001246\n",
        " ..      ...         ...\n",
        " 12       12    0.000000\n",
        " 29       29    0.000000\n",
        " 11       11    0.000000\n",
        " 10       10    0.000000\n",
        " 8         8    0.000000\n",
        " 6         6    0.000000\n",
        " 5         5    0.000000\n",
        " 4         4    0.000000\n",
        " 3         3    0.000000\n",
        " 23       23    0.000000\n",
        " 33       33    0.000000\n",
        " 56       56    0.000000\n",
        " 44       44    0.000000\n",
        " 55       55    0.000000\n",
        " 54       54    0.000000\n",
        " 53       53    0.000000\n",
        " 49       49    0.000000\n",
        " 47       47    0.000000\n",
        " 46       46    0.000000\n",
        " 45       45    0.000000\n",
        " 43       43    0.000000\n",
        " 35       35    0.000000\n",
        " 42       42    0.000000\n",
        " 41       41    0.000000\n",
        " 40       40    0.000000\n",
        " 39       39    0.000000\n",
        " 38       38    0.000000\n",
        " 37       37    0.000000\n",
        " 36       36    0.000000\n",
        " 99       99    0.000000\n",
        " \n",
        " [100 rows x 2 columns]}"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `Fit` step returns the fitted estimator object as well as a dataframe containing the names of features and their importances."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's add one final step to our pipeline to generate predictions on the test set of our classification data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predict = drain.model.Predict(inputs=[fit, data])\n",
      "predict.execute()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tPredict(inputs=[Fit(inputs=[Construct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=1), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t  prefit=False, return_estimator=True, return_feature_importances=True,\n",
        "\t  return_predictions=False), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t    prefit=True, return_estimator=False, return_feature_importances=False,\n",
        "\t    return_predictions=True)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Predicting 593 examples\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 106,
       "text": [
        "{'y':      true  score\n",
        " 0       1      1\n",
        " 4       0      0\n",
        " 6       1      1\n",
        " 9       1      1\n",
        " 12      0      1\n",
        " 13      1      1\n",
        " 14      0      1\n",
        " 16      1      0\n",
        " 17      0      0\n",
        " 20      1      1\n",
        " 21      0      1\n",
        " 22      1      1\n",
        " 24      0      0\n",
        " 25      1      1\n",
        " 27      1      1\n",
        " 29      0      1\n",
        " 30      1      1\n",
        " 33      0      1\n",
        " 34      0      0\n",
        " 35      1      1\n",
        " 36      0      1\n",
        " 38      1      0\n",
        " 39      1      1\n",
        " 41      0      1\n",
        " 42      1      1\n",
        " 43      0      0\n",
        " 44      0      1\n",
        " 47      1      1\n",
        " 51      1      1\n",
        " 52      1      1\n",
        " ..    ...    ...\n",
        " 941     0      0\n",
        " 942     1      0\n",
        " 945     0      0\n",
        " 947     0      0\n",
        " 948     0      0\n",
        " 950     1      1\n",
        " 953     0      1\n",
        " 954     0      1\n",
        " 958     1      1\n",
        " 962     1      1\n",
        " 964     1      1\n",
        " 965     0      0\n",
        " 966     0      0\n",
        " 969     1      1\n",
        " 970     1      1\n",
        " 972     0      0\n",
        " 973     1      1\n",
        " 974     0      0\n",
        " 975     0      0\n",
        " 977     0      1\n",
        " 980     1      1\n",
        " 982     0      0\n",
        " 983     0      0\n",
        " 984     0      1\n",
        " 986     1      0\n",
        " 990     0      0\n",
        " 993     1      0\n",
        " 994     0      1\n",
        " 995     1      1\n",
        " 998     1      1\n",
        " \n",
        " [593 rows x 2 columns]}"
       ]
      }
     ],
     "prompt_number": 106
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Predict method returns a dataframe with a `score` column containing the predictions of the estimator and a `true` column containing the true outcomes."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `drain.model` module contains a variety of metrics which can be run directly on the predict object:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "drain.model.auc(predict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 107,
       "text": [
        "0.75378251939753538"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "drain.model.baseline(predict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 108,
       "text": [
        "0.47217537942664417"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "drain.model.precision(predict, k=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 109,
       "text": [
        "0.90000000000000002"
       ]
      }
     ],
     "prompt_number": 109
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can retrieve the results of any step that has been run through the `get_result` method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predict.get_result()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 110,
       "text": [
        "{'y':      true  score\n",
        " 0       1      1\n",
        " 4       0      0\n",
        " 6       1      1\n",
        " 9       1      1\n",
        " 12      0      1\n",
        " 13      1      1\n",
        " 14      0      1\n",
        " 16      1      0\n",
        " 17      0      0\n",
        " 20      1      1\n",
        " 21      0      1\n",
        " 22      1      1\n",
        " 24      0      0\n",
        " 25      1      1\n",
        " 27      1      1\n",
        " 29      0      1\n",
        " 30      1      1\n",
        " 33      0      1\n",
        " 34      0      0\n",
        " 35      1      1\n",
        " 36      0      1\n",
        " 38      1      0\n",
        " 39      1      1\n",
        " 41      0      1\n",
        " 42      1      1\n",
        " 43      0      0\n",
        " 44      0      1\n",
        " 47      1      1\n",
        " 51      1      1\n",
        " 52      1      1\n",
        " ..    ...    ...\n",
        " 941     0      0\n",
        " 942     1      0\n",
        " 945     0      0\n",
        " 947     0      0\n",
        " 948     0      0\n",
        " 950     1      1\n",
        " 953     0      1\n",
        " 954     0      1\n",
        " 958     1      1\n",
        " 962     1      1\n",
        " 964     1      1\n",
        " 965     0      0\n",
        " 966     0      0\n",
        " 969     1      1\n",
        " 970     1      1\n",
        " 972     0      0\n",
        " 973     1      1\n",
        " 974     0      0\n",
        " 975     0      0\n",
        " 977     0      1\n",
        " 980     1      1\n",
        " 982     0      0\n",
        " 983     0      0\n",
        " 984     0      1\n",
        " 986     1      0\n",
        " 990     0      0\n",
        " 993     1      0\n",
        " 994     0      1\n",
        " 995     1      1\n",
        " 998     1      1\n",
        " \n",
        " [593 rows x 2 columns]}"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## More on workflow execution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's redefine the above workflow using a function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def prediction_workflow():\n",
      "    # generate the data including a training and test split\n",
      "    data = drain.data.ClassificationData(target=True, n_samples=1000, n_features=100)\n",
      "    # construct a random forest estimator\n",
      "    estimator = drain.step.Construct('sklearn.ensemble.RandomForestClassifier', n_estimators=1)\n",
      "    # fit the estimator\n",
      "    fit = drain.model.Fit(inputs=[estimator, data], return_estimator=True, return_feature_importances=True)\n",
      "    # make predictions\n",
      "    return drain.model.Predict(inputs=[fit, data])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predict2 = prediction_workflow()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 112
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that step execution is recursive, that is the `execute` method will ensure that all inputs, and inputs of inputs, etc. have been run before running the given step:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predict2.execute()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tConstruct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=1)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tClassificationData(n_features=100, n_samples=1000)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tFit(inputs=[Construct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=1), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t  prefit=False, return_estimator=True, return_feature_importances=True,\n",
        "\t  return_predictions=False)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Fitting with 386 examples, 100 features\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tPredict(inputs=[Fit(inputs=[Construct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=1), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t  prefit=False, return_estimator=True, return_feature_importances=True,\n",
        "\t  return_predictions=False), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t    prefit=True, return_estimator=False, return_feature_importances=False,\n",
        "\t    return_predictions=True)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Predicting 614 examples\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 113,
       "text": [
        "{'y':      true  score\n",
        " 1       1      1\n",
        " 2       0      1\n",
        " 3       1      1\n",
        " 6       1      1\n",
        " 8       0      0\n",
        " 9       0      0\n",
        " 14      0      1\n",
        " 16      0      0\n",
        " 17      0      0\n",
        " 18      0      0\n",
        " 19      1      1\n",
        " 20      1      1\n",
        " 23      1      0\n",
        " 24      1      1\n",
        " 25      0      0\n",
        " 26      1      1\n",
        " 28      0      1\n",
        " 31      0      0\n",
        " 32      0      0\n",
        " 35      0      0\n",
        " 37      1      1\n",
        " 39      1      1\n",
        " 41      1      0\n",
        " 42      1      1\n",
        " 43      1      0\n",
        " 45      0      1\n",
        " 46      1      1\n",
        " 48      1      0\n",
        " 49      0      0\n",
        " 50      1      1\n",
        " ..    ...    ...\n",
        " 943     1      1\n",
        " 945     1      1\n",
        " 946     0      0\n",
        " 947     0      1\n",
        " 948     0      0\n",
        " 950     0      0\n",
        " 951     1      0\n",
        " 952     1      1\n",
        " 953     0      0\n",
        " 954     0      0\n",
        " 956     1      0\n",
        " 959     1      1\n",
        " 960     1      1\n",
        " 963     1      1\n",
        " 965     0      0\n",
        " 969     0      0\n",
        " 970     1      1\n",
        " 971     0      0\n",
        " 973     0      0\n",
        " 976     1      1\n",
        " 978     1      1\n",
        " 980     1      1\n",
        " 983     0      1\n",
        " 984     1      1\n",
        " 988     0      0\n",
        " 990     0      0\n",
        " 991     1      1\n",
        " 992     1      0\n",
        " 993     1      1\n",
        " 994     0      0\n",
        " \n",
        " [614 rows x 2 columns]}"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The steps of a workflow form a network (a directed acyclic graph or DAG, to be precise)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## A more complicated workflow"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In practice we want to train many models on a given dataset. Let's define a workflow that searches over the number of trees in the random forest model:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def n_estimator_search():\n",
      "    data = drain.data.ClassificationData(target=True, n_samples=1000, n_features=100)\n",
      "    \n",
      "    predict = []\n",
      "    for n_estimators in range(1, 4):\n",
      "        estimator = drain.step.Construct('sklearn.ensemble.RandomForestClassifier', n_estimators=n_estimators, name = 'estimator')\n",
      "        fit = drain.model.Fit(inputs=[estimator, data], return_estimator=True, return_feature_importances=True)\n",
      "        predict.append(drain.model.Predict(inputs=[fit, data]))\n",
      "        \n",
      "    return predict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions = n_estimator_search()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for p in predictions:\n",
      "    p.execute()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tConstruct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=1)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tClassificationData(n_features=100, n_samples=1000)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tFit(inputs=[Construct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=1), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t  prefit=False, return_estimator=True, return_feature_importances=True,\n",
        "\t  return_predictions=False)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Fitting with 390 examples, 100 features\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tPredict(inputs=[Fit(inputs=[Construct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=1), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t  prefit=False, return_estimator=True, return_feature_importances=True,\n",
        "\t  return_predictions=False), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t    prefit=True, return_estimator=False, return_feature_importances=False,\n",
        "\t    return_predictions=True)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Predicting 610 examples\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tConstruct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=2)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tFit(inputs=[Construct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=2), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t  prefit=False, return_estimator=True, return_feature_importances=True,\n",
        "\t  return_predictions=False)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Fitting with 390 examples, 100 features\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tPredict(inputs=[Fit(inputs=[Construct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=2), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t  prefit=False, return_estimator=True, return_feature_importances=True,\n",
        "\t  return_predictions=False), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t    prefit=True, return_estimator=False, return_feature_importances=False,\n",
        "\t    return_predictions=True)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Predicting 610 examples\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tConstruct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=3)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tFit(inputs=[Construct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=3), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t  prefit=False, return_estimator=True, return_feature_importances=True,\n",
        "\t  return_predictions=False)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Fitting with 390 examples, 100 features\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running\n",
        "\tPredict(inputs=[Fit(inputs=[Construct(__class_name__='sklearn.ensemble.RandomForestClassifier',\n",
        "\t     n_estimators=3), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t  prefit=False, return_estimator=True, return_feature_importances=True,\n",
        "\t  return_predictions=False), ClassificationData(n_features=100, n_samples=1000)],\n",
        "\t    prefit=True, return_estimator=False, return_feature_importances=False,\n",
        "\t    return_predictions=True)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Predicting 610 examples\n"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that the ClassificationData step was only run once."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Drain provides some additional utilities for model exploration in the `drain.explore` module:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from drain import explore\n",
      "df = explore.to_dataframe(predictions)\n",
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>n_estimators</th>\n",
        "      <th>step</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>1</td>\n",
        "      <td>Predict(inputs=[Fit(inputs=[Construct(__class_...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>2</td>\n",
        "      <td>Predict(inputs=[Fit(inputs=[Construct(__class_...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>3</td>\n",
        "      <td>Predict(inputs=[Fit(inputs=[Construct(__class_...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 117,
       "text": [
        "   n_estimators                                               step\n",
        "0             1  Predict(inputs=[Fit(inputs=[Construct(__class_...\n",
        "1             2  Predict(inputs=[Fit(inputs=[Construct(__class_...\n",
        "2             3  Predict(inputs=[Fit(inputs=[Construct(__class_..."
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from drain import model\n",
      "explore.apply(df, model.auc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 118,
       "text": [
        "n_estimators\n",
        "1    0.657921\n",
        "2    0.833586\n",
        "3    0.899431\n",
        "Name: step, dtype: float64"
       ]
      }
     ],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "explore.apply(df, model.precision_series).plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 119,
       "text": [
        "<matplotlib.axes._subplots.AxesSubplot at 0x7f01c50af610>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEACAYAAABMEua6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f01c4f72c90>"
       ]
      }
     ],
     "prompt_number": 119
    }
   ],
   "metadata": {}
  }
 ]
}